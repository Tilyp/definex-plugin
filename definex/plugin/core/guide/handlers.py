"""
èœå•å¤„ç†å™¨å±‚
è´Ÿè´£å°†ç”¨æˆ·è¾“å…¥è½¬åŒ–ä¸ºä¸šåŠ¡æ“ä½œ
"""
from pathlib import Path
from typing import Optional

from definex.exception.exceptions import ConfigException
from definex.plugin.config import (
    ConfigManager, LLMModelConfig, ModelProvider
)
from .views import UIManager


class LLMHandler:
    """LLM é…ç½®å¤„ç†å™¨"""

    def __init__(self, ui: UIManager, config_mgr: ConfigManager):
        self.ui = ui
        self.config_mgr = config_mgr

    def show_menu(self) -> Optional[str]:
        while True:
            """æ˜¾ç¤º LLM èœå•å¹¶å¤„ç†ç”¨æˆ·é€‰æ‹©"""
            self.ui.show_header("âš™ï¸ LLM é…ç½®å‘å¯¼")
            # æ˜¾ç¤ºå½“å‰é…ç½®
            self._show_current_status()
            # æ˜¾ç¤ºèœå•
            menu = self.ui.menus.render_llm_menu()
            self.ui.console.print(menu)
            choice = self.ui.forms.prompt_choice(["1", "2", "3", "4", "5", "0"], default="0")
            if choice == "1":
                return self.add_model()
            elif choice == "2":
                return self.switch_model()
            elif choice == "3":
                return self.remove_model()
            elif choice == "4":
                return self.show_all_models()
            elif choice == "5":
                return self.validate_llm_config()
            elif choice == "0":
                self._handle_llm_config_exit()
                break

    def _show_current_status(self) -> None:
        """æ˜¾ç¤ºå½“å‰ LLM é…ç½®çŠ¶æ€"""
        current = self.config_mgr.get_current_llm_config()
        if current:
            self.ui.console.print(f"[bold cyan]å½“å‰æ¨¡å‹:[/bold cyan] [green]{current.get('model')}[/green]")
        else:
            self.ui.status.show_warning("æœªé…ç½®ä»»ä½• LLM æ¨¡å‹")

    def add_model(self) -> Optional[str]:
        """æ·»åŠ æ–°æ¨¡å‹"""
        self.ui.show_header("æ·»åŠ  LLM æ¨¡å‹")

        try:
            name = self.ui.forms.prompt_string("æ¨¡å‹åç§°", default="gpt-4")

            # é€‰æ‹©æä¾›å•†
            providers = [p.value for p in ModelProvider]
            provider_str = self.ui.forms.prompt_choice(providers, default=providers[0])
            provider = ModelProvider(provider_str)

            api_key = self.ui.forms.prompt_string("API Key (å¿…å¡«)", password=True)
            base_url = self.ui.forms.prompt_string("Base URL", default="https://api.deepseek.com")

            temperature = self.ui.forms.prompt_int("æ¸©åº¦ (0-2)", default=7) / 10
            max_tokens = self.ui.forms.prompt_int("æœ€å¤§ Token æ•°", default=2000)

            model_config = LLMModelConfig(
                name=name,
                provider=provider,
                api_key=api_key,
                base_url=base_url,
                temperature=temperature,
                max_tokens=max_tokens
            )

            self.config_mgr.add_or_update_llm_model(model_config, set_as_current=True)
            self.ui.status.show_success(f"æ¨¡å‹ {name} å·²æ·»åŠ å¹¶è®¾ä¸ºå½“å‰æ¨¡å‹")
            return "model_added"
        except Exception as e:
            self.ui.status.show_error(str(e))
            return None

    def switch_model(self) -> Optional[str]:
        """åˆ‡æ¢å½“å‰æ¨¡å‹"""
        models = self.config_mgr.get_llm_model_names()

        if not models:
            self.ui.status.show_warning("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            return None

        self.ui.console.print("\n[bold]å¯ç”¨æ¨¡å‹:[/bold]")
        for i, model in enumerate(models, 1):
            self.ui.console.print(f"{i}. {model}")

        choice = self.ui.forms.prompt_choice([str(i) for i in range(1, len(models) + 1)], default="1")

        try:
            selected_model = models[int(choice) - 1]
            self.config_mgr.set_current_llm_model(selected_model)
            self.ui.status.show_success(f"å·²åˆ‡æ¢åˆ°æ¨¡å‹: {selected_model}")
            return "model_switched"
        except (ValueError, IndexError):
            self.ui.status.show_error("æ— æ•ˆçš„é€‰æ‹©")
            return None

    def remove_model(self) -> Optional[str]:
        """åˆ é™¤æ¨¡å‹"""
        models = self.config_mgr.get_llm_model_names()

        if not models:
            self.ui.status.show_warning("æ²¡æœ‰å¯åˆ é™¤çš„æ¨¡å‹")
            return None

        self.ui.console.print("\n[bold]å¯ç”¨æ¨¡å‹:[/bold]")
        for i, model in enumerate(models, 1):
            self.ui.console.print(f"{i}. {model}")

        choice = self.ui.forms.prompt_choice([str(i) for i in range(1, len(models) + 1)], default="1")

        try:
            model_to_remove = models[int(choice) - 1]

            if self.ui.forms.prompt_confirm(f"[red]ç¡®è®¤åˆ é™¤æ¨¡å‹ '{model_to_remove}'ï¼Ÿ[/red]", default=False):
                self.config_mgr.remove_llm_model(model_to_remove)
                self.ui.status.show_success(f"æ¨¡å‹ {model_to_remove} å·²åˆ é™¤")
                return "model_removed"
        except (ValueError, IndexError):
            self.ui.status.show_error("æ— æ•ˆçš„é€‰æ‹©")
        return None

    def show_all_models(self) -> Optional[str]:
        """å±•ç¤ºæ‰€æœ‰æ¨¡å‹"""
        self.ui.console.print("\n[bold cyan]ğŸ¤– LLM é…ç½®:[/bold cyan]")
        models_config = self.config_mgr.get_llm_model()
        table = self.ui.tables.render_models_table(
            models_config.get_all_config(),
            models_config.get_current_config())
        self.ui.console.print(table)

    def validate_llm_config(self):
        self.ui.show_header("ğŸ¤– æ ¡éªŒæ‰€æœ‰æ¨¡å‹é…ç½®:")
        result = self.config_mgr.validate_llm_config()
        if len(result) != 0:
            table = self.ui.tables.render_validate_models_table(result)
            self.ui.console.print(table)
        else:
            self.ui.console.print("\n[green]âœ… æ‰€æœ‰æ¨¡å‹é…ç½®æ ¡éªŒé€šè¿‡:[/green]")

    def _handle_llm_config_exit(self):
        self.ui.show_footer()

class PushHandler:
    """Push é…ç½®å¤„ç†å™¨"""

    def __init__(self, ui: UIManager, config_mgr: ConfigManager):
        self.ui = ui
        self.config_mgr = config_mgr

    def show_menu(self) -> Optional[str]:
        while True:
            """æ˜¾ç¤º Push èœå•"""
            self.ui.show_header("ğŸš€ å‘å¸ƒç¯å¢ƒé…ç½®å‘å¯¼")

            # æ˜¾ç¤ºå½“å‰é…ç½®
            self._show_current_status()

            # æ˜¾ç¤ºèœå•
            menu = self.ui.menus.render_push_menu()
            self.ui.console.print(menu)

            choice = self.ui.forms.prompt_choice(["1", "2", "3", "0"], default="0")

            if choice == "1":
                self.add_environment()
            elif choice == "2":
                self.set_default()
            elif choice == "3":
                self.remove_environment()
            elif choice == "0":
                self.ui.show_footer()
                break

    def _show_current_status(self) -> None:
        """æ˜¾ç¤ºå½“å‰å‘å¸ƒç¯å¢ƒçŠ¶æ€"""
        push_config = self.config_mgr.get_push_config()
        if push_config.default_environment:
            self.ui.console.print(f"[bold cyan]é»˜è®¤ç¯å¢ƒ:[/bold cyan] [magenta]{push_config.default_environment}[/magenta]")
        else:
            self.ui.status.show_warning("æœªé…ç½®ä»»ä½•å‘å¸ƒç¯å¢ƒ")

    def add_environment(self) -> Optional[str]:
        """æ·»åŠ æˆ–æ›´æ–°å‘å¸ƒç¯å¢ƒ"""
        self.ui.show_header("æ·»åŠ /æ›´æ–°å‘å¸ƒç¯å¢ƒ")

        env_name = self.ui.forms.prompt_string("ç¯å¢ƒåç§° (dev/prod)", default="dev")
        url = self.ui.forms.prompt_string("å‘å¸ƒåœ°å€ (URL)")
        token = self.ui.forms.prompt_string("è®¤è¯ Token", password=True)
        description = self.ui.forms.prompt_string("ç¯å¢ƒæè¿° (å¯é€‰)", default="")

        try:
            self.config_mgr.set_env_config(
                env_name=env_name,
                url=url,
                token=token,
                description=description
            )
            self.ui.status.show_success(f"ç¯å¢ƒ '{env_name}' å·²é…ç½®")
            return "env_added"
        except ConfigException as e:
            self.ui.status.show_error(str(e))
            return None

    def set_default(self) -> Optional[str]:
        """è®¾ç½®é»˜è®¤ç¯å¢ƒ"""
        environments = self.config_mgr.get_environment_names()

        if not environments:
            self.ui.status.show_warning("æ²¡æœ‰å¯ç”¨çš„ç¯å¢ƒ")
            return None

        self.ui.console.print("\n[bold]å¯ç”¨ç¯å¢ƒ:[/bold]")
        for i, env in enumerate(environments, 1):
            self.ui.console.print(f"{i}. {env}")

        choice = self.ui.forms.prompt_choice([str(i) for i in range(1, len(environments) + 1)], default="1")

        try:
            selected_env = environments[int(choice) - 1]
            push_config = self.config_mgr.get_push_config()
            push_config.default_environment = selected_env
            self.config_mgr.save_push_config(push_config)
            self.ui.status.show_success(f"å·²è®¾ç½®é»˜è®¤ç¯å¢ƒ: {selected_env}")
            return "default_set"
        except (ValueError, IndexError):
            self.ui.status.show_error("æ— æ•ˆçš„é€‰æ‹©")
            return None

    def remove_environment(self) -> Optional[str]:
        """åˆ é™¤ç¯å¢ƒ"""
        environments = self.config_mgr.get_environment_names()

        if not environments:
            self.ui.status.show_warning("æ²¡æœ‰å¯åˆ é™¤çš„ç¯å¢ƒ")
            return None

        self.ui.console.print("\n[bold]å¯ç”¨ç¯å¢ƒ:[/bold]")
        for i, env in enumerate(environments, 1):
            self.ui.console.print(f"{i}. {env}")

        choice = self.ui.forms.prompt_choice([str(i) for i in range(1, len(environments) + 1)], default="1")

        try:
            env_to_remove = environments[int(choice) - 1]

            if self.ui.forms.prompt_confirm(f"[red]ç¡®è®¤åˆ é™¤ç¯å¢ƒ '{env_to_remove}'ï¼Ÿ[/red]", default=False):
                self.config_mgr.remove_environment(env_to_remove)
                self.ui.status.show_success(f"ç¯å¢ƒ {env_to_remove} å·²åˆ é™¤")
                return "env_removed"
        except (ValueError, IndexError):
            self.ui.status.show_error("æ— æ•ˆçš„é€‰æ‹©")

        return None


class ProjectHandler:
    """é¡¹ç›®é…ç½®å¤„ç†å™¨"""

    def __init__(self, ui: UIManager, config_mgr: ConfigManager):
        self.ui = ui
        self.config_mgr = config_mgr

    def show_menu(self) -> Optional[str]:
        """æ˜¾ç¤ºé¡¹ç›®é…ç½®èœå•"""
        self.ui.show_header("ğŸ› ï¸ é¡¹ç›®é…ç½®ç®¡ç†")

        # æ˜¾ç¤ºå½“å‰è®¾ç½®
        self._show_current_settings()

        menu = self.ui.menus.render_project_menu()
        self.ui.console.print(menu)

        choice = self.ui.forms.prompt_choice(["1", "2", "3", "4", "0"], default="0")

        if choice == "1":
            return self.modify_chat_config()
        elif choice == "2":
            return self.export_config()
        elif choice == "3":
            return self.import_config()
        elif choice == "4":
            return self.reset_config()

        return None

    def _show_current_settings(self) -> None:
        """æ˜¾ç¤ºå½“å‰è®¾ç½®"""
        chat_config = self.config_mgr.get_chat_config()

        settings = {
            "æœ€å¤§å†å²é•¿åº¦": chat_config.max_history_length,
            "æœ€å¤§ä¸Šä¸‹æ–‡ Token": chat_config.max_context_tokens,
            "å¯ç”¨æµå¼è¾“å‡º": "âœ… æ˜¯" if chat_config.enable_streaming else "âŒ å¦",
            "è‡ªåŠ¨ä¿å­˜ä»£ç ": "âœ… æ˜¯" if chat_config.auto_save_code else "âŒ å¦",
        }

        table = self.ui.tables.render_config_table(settings, "å½“å‰èŠå¤©é…ç½®")
        self.ui.console.print(table)

    def modify_chat_config(self) -> Optional[str]:
        """ä¿®æ”¹èŠå¤©é…ç½®"""
        self.ui.show_header("ä¿®æ”¹èŠå¤©é…ç½®")

        current = self.config_mgr.get_chat_config()

        max_history = self.ui.forms.prompt_int(
            "æœ€å¤§å†å²è®°å½•é•¿åº¦",
            default=current.max_history_length
        )

        max_tokens = self.ui.forms.prompt_int(
            "æœ€å¤§ä¸Šä¸‹æ–‡ Token",
            default=current.max_context_tokens
        )

        streaming = self.ui.forms.prompt_confirm(
            "å¯ç”¨æµå¼è¾“å‡º",
            default=current.enable_streaming
        )

        auto_save = self.ui.forms.prompt_confirm(
            "è‡ªåŠ¨ä¿å­˜ä»£ç ",
            default=current.auto_save_code
        )

        try:
            from definex.plugin.config import ChatConfig
            new_config = ChatConfig(
                max_history_length=max_history,
                max_context_tokens=max_tokens,
                enable_streaming=streaming,
                auto_save_code=auto_save,
                code_output_dir=current.code_output_dir,
                default_filename=current.default_filename
            )
            self.config_mgr.save_chat_config(new_config)
            self.ui.status.show_success("èŠå¤©é…ç½®å·²æ›´æ–°")
            return "config_updated"
        except Exception as e:
            self.ui.status.show_error(str(e))
            return None

    def export_config(self) -> Optional[str]:
        """å¯¼å‡ºé…ç½®"""
        self.ui.show_header("å¯¼å‡ºé…ç½®")

        export_path = self.ui.forms.prompt_string(
            "å¯¼å‡ºæ–‡ä»¶è·¯å¾„",
            default=str(Path.home() / ".definex" / "config_export.yaml")
        )

        include_secrets = self.ui.forms.prompt_confirm("åŒ…å«æ•æ„Ÿä¿¡æ¯", default=False)

        try:
            success = self.config_mgr.export_config(Path(export_path), include_secrets)
            if success:
                self.ui.status.show_success(f"é…ç½®å·²å¯¼å‡ºåˆ°: {export_path}")
                return "exported"
        except Exception as e:
            self.ui.status.show_error(str(e))

        return None

    def import_config(self) -> Optional[str]:
        """å¯¼å…¥é…ç½®"""
        self.ui.show_header("å¯¼å…¥é…ç½®")

        import_path = self.ui.forms.prompt_string("å¯¼å…¥æ–‡ä»¶è·¯å¾„")
        merge = self.ui.forms.prompt_confirm("åˆå¹¶ç°æœ‰é…ç½®", default=True)

        try:
            if not Path(import_path).exists():
                self.ui.status.show_error(f"æ–‡ä»¶ä¸å­˜åœ¨: {import_path}")
                return None

            success = self.config_mgr.import_config(Path(import_path), merge)
            if success:
                self.ui.status.show_success("é…ç½®å·²å¯¼å…¥")
                return "imported"
        except Exception as e:
            self.ui.status.show_error(str(e))

        return None

    def reset_config(self) -> Optional[str]:
        """é‡ç½®é…ç½®"""
        if self.ui.forms.prompt_confirm("[red]âš ï¸ ç¡®è®¤é‡ç½®æ‰€æœ‰é…ç½®ä¸ºé»˜è®¤å€¼ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€![/red]", default=False):
            try:
                self.config_mgr.reset_config()
                self.ui.status.show_success("é…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
                return "reset"
            except Exception as e:
                self.ui.status.show_error(str(e))

        return None


class StatusHandler:
    """çŠ¶æ€æ˜¾ç¤ºå¤„ç†å™¨"""

    def __init__(self, ui: UIManager, config_mgr: ConfigManager):
        self.ui = ui
        self.config_mgr = config_mgr

    def show_full_status(self) -> None:
        """æ˜¾ç¤ºå®Œæ•´é…ç½®çŠ¶æ€"""
        self.ui.show_header("ğŸ“‹ å…¨å±€é…ç½®çŠ¶æ€ (å·²è„±æ•)")

        masked = self.config_mgr.get_masked_config()

        # LLM ä¿¡æ¯
        if "llm" in masked:
            self.show_llm_status(masked)

        # Push ä¿¡æ¯
        if "push" in masked:
            self.show_push_status(masked)

        # Chat ä¿¡æ¯
        if "chat" in masked:
            self.show_chat_status(masked)

    def show_llm_status(self, masked):
        llm_data = masked.get("llm", {})
        self.ui.console.print("\n[bold cyan]ğŸ¤– LLM é…ç½®:[/bold cyan]")
        current_model = llm_data.get("current_model", None)
        if "models" in llm_data:
            table = self.ui.tables.render_models_table(llm_data["models"], current_model)
            self.ui.console.print(table)

    def show_push_status(self, masked):
        push_data = masked.get("push", {})
        self.ui.console.print("\n[bold cyan]ğŸš€ å‘å¸ƒé…ç½®:[/bold cyan]")
        push_table_data = {
            "é»˜è®¤ç¯å¢ƒ": push_data.get("default", "æœªè®¾ç½®"),
            "ç¯å¢ƒæ•°": str(len(push_data.get("environments", {})))
        }
        table = self.ui.tables.render_config_table(push_table_data)
        self.ui.console.print(table)

    def show_chat_status(self, masked):
        chat_data = masked.get("chat", {})
        self.ui.console.print("\n[bold cyan]ğŸ’¬ èŠå¤©é…ç½®:[/bold cyan]")
        chat_table_data = {
            "æœ€å¤§å†å²": chat_data.get("max_history_length", 10),
            "æœ€å¤§ Token": chat_data.get("max_context_tokens", 4000),
            "æµå¼è¾“å‡º": "âœ… æ˜¯" if chat_data.get("enable_streaming") else "âŒ å¦"
        }
        table = self.ui.tables.render_config_table(chat_table_data)
        self.ui.console.print(table)